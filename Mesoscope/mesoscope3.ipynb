{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?  =  variable name, possibly with indexing/slicing  \n",
    "??? = function / class name  \n",
    "?????? = complex expression containing variables, functions etc  \n",
    "???B??? = complex expression that must contain \"B\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting behavior from mouse face videos\n",
    "\n",
    "### Load in mouse face videos\n",
    "\n",
    "Using the `pyav` library, load in the first 3000 frames of this movie. It is a gray-scale movie so we only take one channel of the RGB output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av, os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import skew\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from facemap import utils\n",
    "\n",
    "### PUT HERE THE PATH TO THE MOVIE\n",
    "root = '/home/neuraldata/data/meso/'\n",
    "mouse_name = 'TX39'\n",
    "moviename = os.path.join(root, mouse_name, 'cam1_TX39.avi')\n",
    "\n",
    "# open the video for reading\n",
    "container = av.open(moviename)\n",
    "container.streams.video[0].thread_type = 'AUTO'\n",
    "nframes = container.streams[0].duration\n",
    "\n",
    "# read the movie frame by frame\n",
    "k=0\n",
    "for frame in container.decode(video=0):\n",
    "    array = frame.to_ndarray(format='rgb24')\n",
    "    array = array[:,:,0] # take the first channel of the frame (red)\n",
    "    if k==0:\n",
    "        # initialize imgs to an array of zeros of type uint8, size 3000 by movie height by movie width\n",
    "        imgs = np.???((?, ?, ?), '???') \n",
    "    imgs[k] = array\n",
    "    k+=1\n",
    "    if k==3000:\n",
    "        break   \n",
    "    \n",
    "# convert imgs to float32 (or \"'\"single\")\n",
    "imgs = np.???(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the motion energy\n",
    "\n",
    "To capture behavior, we do not necessarily care where the mouse's whisker is - rather we care if it's moving and in what patterns. To compute movement features we start by: 1) taking the difference between frames, 2) taking the absolute value of this because we want overall movement, regardless of sign. This absolute value of the difference is the **motion energy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion energy\n",
    "motion = np.???(np.???(imgs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some frames\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "# example frame\n",
    "ax=fig.add_subplot(1,3,1)\n",
    "ax.imshow(?, cmap='gray') # display frame 100\n",
    "ax.set_title('example frame')\n",
    "\n",
    "# average mouse face\n",
    "ax=fig.add_subplot(1,3,2)\n",
    "ax.imshow(np.???(imgs, axis=0), cmap='gray') # display the mean frame\n",
    "ax.set_title('average frame')\n",
    "\n",
    "# average motion energy\n",
    "ax=fig.add_subplot(1,3,3)\n",
    "ax.imshow(np.mean(?, axis=0), cmap='gray') # display the mean motion energy\n",
    "ax.set_title('average motion energy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce dimensionality of motion energy\n",
    "\n",
    "Motion energy has dimensions = number of frames by number of pixels. We want to only keep the top 100 principal components of this motion energy. Let's compute the top 100 \"spatial\" components of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion = np.reshape(motion, (motion.shape[0],-1))\n",
    "motion = motion - ?????? # subtract the mean across time\n",
    "\n",
    "# take the principal components of these mean-centered motion energy frames\n",
    "from sklearn.decomposition import PCA\n",
    "ncomps = 100\n",
    "# fit a PCA model to the motion variable\n",
    "pca_model = ???ncomps???\n",
    "\n",
    "print('spatial components of size (%d, %d)'%pca_model.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these spatial components. Observe that most of the variation occurs in the whisker pad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NT, Ly,Lx = ?.shape # movie dimensions\n",
    "motMask = np.reshape(pca_model.components_, (?, Ly, Lx)) # reshape PCA components\n",
    "plt.figure(figsize=(15,8))\n",
    "for i in range(15):\n",
    "    ax=plt.subplot(3,5,i+1)\n",
    "    # plot the i-th motion energy mask, use the blue-white-red colormap, set saturation limits of -0.01 and 0.01\n",
    "    ax.imshow(?, ?=?, ?=-?, ?=?)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project spatial components onto all frames\n",
    "\n",
    "To compute the low-dimensional representation of the motion energy across time, we need to now PROJECT these spatial components onto the the motion energy for each frame.\n",
    "\n",
    "The principal components are the same as the $U$ in singular value decomposition, where the singular value decomposition is\n",
    "$$ X \\approx USV^\\top $$\n",
    "\n",
    "Let's multiply $U^\\top$ on both sides, recall that $U U^\\top = I$ because $U$ is an orthonormal matrix.\n",
    "$$ U^\\top X = S V^\\top $$\n",
    "\n",
    "So $U^\\top X$ gives the right singular vectors scaled by the variance of each component. We will use this instead of using $S^{-1} U^\\top X$. Why might we want them to be weighted by their true variance in the video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the temporal coefficients for the principal components\n",
    "motSVD = model_pca.??? @ ?.T # project the raw movie into the spatial components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRACES\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "\n",
    "colormap = plt.cm.magma\n",
    "colors   = colormap(np.linspace(0,1,10)) # create an array of colors from one end to the other of the colormap\n",
    "for n in range(10):\n",
    "    plt.plot(motSVD[n] + ?*?, color=cmap[n], zorder=10-n) # spread out the traces in Y for visualization\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
